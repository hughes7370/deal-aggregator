# Deployment Setup Instructions

We will be using Render for both the frontend and backend applications. Both services can be deployed from the same repository by configuring different root directories in Render.

## Frontend Application Overview:

Our frontend is a Next.js application that handles user authentication and preference management:

1. Application Structure:
   - `/frontend/src/app`: Main application routes and pages
   - `/frontend/src/components`: Reusable UI components
   - `/frontend/src/app/(auth)`: Authentication routes (sign-in/sign-up)
   - `/frontend/src/app/dashboard`: User dashboard and preferences
   - `/frontend/src/lib`: Shared libraries (Supabase client)
   - `/frontend/src/constants`: Frontend constants and content

2. Key Features:
   - User Authentication:
     * Implemented using Clerk
     * Sign up and sign in pages at /sign-up and /sign-in
     * Protected routes using Clerk middleware
   
   - User Dashboard:
     * Main dashboard at /dashboard
     * Displays user's investment preferences
     * Shows investment range, target industries, and alert frequency
     * Interface to update preferences
   
   - User Preferences:
     * Stored in Supabase database
     * Managed through dashboard interface
     * Includes investment ranges, industries, and alert settings
     * Real-time updates using Supabase client

3. Technology Stack:
   - Next.js 14 (React framework)
   - TypeScript for type safety
   - Tailwind CSS for styling
   - Clerk for authentication
   - Supabase for database

## Backend Application Overview:

Our backend system handles data scraping, storage, and newsletter distribution:

1. Core Components:
   - `/backend/run.py`: Flask application entry point
   - `/backend/src/scrapers`: Individual scrapers for different platforms
   - `/backend/src/api`: API endpoints and listing management
   - `/backend/src/database`: Database operations and Supabase client
   - `/backend/src/services`: Business logic and scheduled tasks

2. Key Features:
   - Automated Listing Scraping:
     * Scrapes business listing platforms (BusinessExits, EmpireFlippers, QuietLight)
     * Extracts listing details, prices, and business metrics
     * Normalizes data across different platforms
     * Stores listings in Supabase database
   
   - Scheduled Tasks:
     * Uses APScheduler for job scheduling
     * Daily scraping at 1 AM UTC
     * Hourly newsletter checks
     * Health checks and monitoring
   
   - Newsletter System:
     * Uses Resend for email delivery
     * Compiles personalized newsletters based on user preferences
     * Matches listings against user criteria
     * Tracks last notification sent

3. Technology Stack:
   - Flask (Python web framework)
   - APScheduler for task scheduling
   - Supabase for database
   - BeautifulSoup4 for web scraping
   - Resend for email delivery

## Deployment Instructions:

### Frontend Deployment:

1. Create a new Web Service in Render
   - Go to render.com and sign in
   - Click "New +" and select "Web Service"
   - Choose the GitHub repository

2. Configure Build and Start Settings:
   - Name: deal-aggregator-frontend
   - Environment: Node
   - Region: Choose closest to target users
   - Branch: main
   - Root Directory: `/frontend`
   - Runtime Environment: Node
   - Build Command: `npm install && npm run build`
   - Start Command: `npm start`
   - Instance Type: Starter (or higher based on needs)
   - Auto-Deploy: Yes

3. Configure Environment Variables:
   Authentication (Clerk):
   - NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY: From Clerk Dashboard -> API Keys
   - CLERK_SECRET_KEY: From Clerk Dashboard -> API Keys
   - CLERK_WEBHOOK_SECRET: From Clerk Dashboard -> Webhooks
   - NEXT_PUBLIC_CLERK_SIGN_IN_URL: /sign-in
   - NEXT_PUBLIC_CLERK_SIGN_UP_URL: /sign-up
   - NEXT_PUBLIC_CLERK_AFTER_SIGN_IN_URL: /dashboard/
   - NEXT_PUBLIC_CLERK_AFTER_SIGN_UP_URL: /dashboard/preferences
   
   Database (Supabase):
   - NEXT_PUBLIC_SUPABASE_URL: From Supabase Project Settings -> API
   - NEXT_PUBLIC_SUPABASE_ANON_KEY: From Supabase Project Settings -> API
   
   Application:
   - NEXT_PUBLIC_APP_URL: Your application URL

4. Pre-Deployment Checklist:
   - Verify all environment variables are set
   - Ensure Clerk authentication is configured:
     * Add deployment URL to Clerk allowed origins
     * Update Clerk redirect URLs
   - Confirm Supabase is properly configured:
     * Database policies are set
     * Row Level Security (RLS) is enabled

### Backend Deployment:

1. Create a new Web Service in Render
   - Go to render.com and sign in
   - Click "New +" and select "Web Service"
   - Choose the same GitHub repository

2. Configure Build and Start Settings:
   - Name: deal-aggregator-backend
   - Environment: Python
   - Region: Choose same region as frontend
   - Branch: main
   - Root Directory: `/backend`
   - Build Command: `pip install -r requirements.txt`
   - Start Command: `python run.py`
   - Instance Type: Standard (recommended for background jobs)
   - Auto-Deploy: Yes

3. Configure Environment Variables:
   Database (Supabase):
   - NEXT_PUBLIC_SUPABASE_URL: From Supabase Project Settings
   - NEXT_PUBLIC_SUPABASE_ANON_KEY: From Supabase Project Settings
   - SUPABASE_SERVICE_ROLE_KEY: From Supabase Project Settings
   
   Email Service (Resend):
   - RESEND_API_KEY: From Resend Dashboard
   - RESEND_FROM_EMAIL: alerts@dealsight.co
   
   Scraper APIs:
   - SERPAPI_KEY: From SerpAPI Dashboard
   - OPENAI_API_KEY: From OpenAI Dashboard
   - SCRAPER_API_KEY: From ScraperAPI Dashboard
   - AGENTQL_API_KEY: From AgentQL Dashboard

   Application Settings:
   - PORT: 5000
   - ENVIRONMENT: production
   - PYTHONPATH: /app/backend

4. Pre-Deployment Checklist:
   - Verify all environment variables are set
   - Ensure Supabase database is properly configured
   - Test scraper configurations
   - Configure Resend email settings

5. Post-Deployment Verification:
   - Health check endpoint responds
   - Scraper test endpoint works
   - Newsletter test endpoint works
   - Background jobs are running
   - Logs are being captured

Note: The backend service needs to run continuously to handle scheduled tasks. Monitor the service's resource usage and adjust the instance type if needed.

